---
title: "oppg 2cd ferdig"
author: "Ida Marie Falnes"
date: "16 februar 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



###Task c)
In this task, `modelA` is used to analyse the connection between $BMI$ and the response. Below, the summary output from the linear regression in R is shown.
```{r, echo=FALSE}

data = read.table("https://www.math.ntnu.no/emner/TMA4268/2018v/data/SYSBPreg3uid.txt")

modelA=lm(-1/sqrt(SYSBP) ~ .,data = data)
summary(modelA)

```

The estimated coefficients can be expressed as $\boldsymbol{\hat\beta}=(\mathbf{X^TX})^{-1}\mathbf{X}^T\mathbf{Y}$, where $\mathbf{X}$ is the design matrix containing all of our data, and $\mathbf{Y}$ is the response variable in our model; $\mathbf{Y}=\mathbf{X}\boldsymbol{\beta}+\boldsymbol{\varepsilon}$. The numerical value of $\hat\beta_{BMI}$ can be read out of the summary: $\hat\beta_{BMI}\approx 3.087 \cdot 10^{-4}$.

The estimated coefficients can be iterpreted as a measure on how much each covariate affects the predicted response. In particular, $\hat\beta_{BMI}$ can be interpreted as the average effect on the response as a consequence of a unit change of the $BMI$-covariate. Comparing it to the other estimated coefficients, it seems like for `modelA`, the $BMI$ covariate has a significant impact on the response. This means that if you keep the other covariates constant and increase the $BMI$ covariate with one unit, the changes in the predicted response is $3.087\cdot10^{-4}$.

99% confidence interval for  $\beta_{BMI}$ is the interval we are $99$% confident to find $\beta_{BMI}$. It can be proven that $\boldsymbol{\hat\beta}$ ~ $N(\boldsymbol\beta,\sigma^2(\mathbf{X^TX})^{-1})$, where $\sigma^2$ is estimated using the relationship $\hat\sigma^2=RSS/(n-p-1)$, where p is the number of covariates estimated, and $\frac{(n-p-1)\hat\sigma^2}{\sigma^2}$~$\chi^2_{n-p-1}$. For the particular coefficient $\hat\beta_{BMI}$, we have that the parameter has the chi-square distribution with $n-2$ degrees of freedom. The $(1-\alpha)100$% confidence interval can then be constructed.

$$
P(-t_{\alpha/2,n-2} \leq\frac{\hat\beta-\beta}{\sqrt{c_{jj}\hat\sigma^2}} \leq t_{\alpha/2,n-2}) = 1-\alpha \\ 
P(\hat\beta_{BMI}-t_{0.005,n-2}\sqrt{c_{jj}\hat\sigma^2} \leq \beta \leq \hat\beta_{BMI}-t_{0.005,n-2}\sqrt{\hat\sigma^2c_{jj}})=1-\alpha
$$
Here, the $c_{jj}$ is the diagonal element of $\mathbf{(X^TX)^{-1}}$ corresponding to $\hat\beta_{BMI}$.

The values needed to compute the estimate of the variance can be found using the output from the fitted model in R. We are interested in the standard error for $\beta_{BMI}$ which gives us the square root of the estimated variance. In our case,  $SE(\hat\beta_{BMI})^2=\frac{\sigma^2}{\sum_{i=1}^{n}}(x_i-\bar x)=2.955 \cdot 10^{-5}$. The confidence interval is given by

$$
\hat\beta_{BMI}\pm t_{\alpha/2,n-2}\cdot SE(\hat\beta_{BMI})
$$
where the t-distribution can be approximated by the normal distribution because $n$ is large. In this case, $\alpha=0.01$, so 
$$
\hat\beta_{BMI}\pm z_{\alpha/2}\cdot SE(\hat\beta_{BMI}),
$$
where $z_{\alpha/2}=z_{0.01/2}=2.576$, so the confidence interval is

$$
[3.087 \cdot 10^{-4} - 2.576 \cdot (2.955 \cdot 10^{-5}), 3.087 \cdot 10^{-4} + 2.576 \cdot (2.955 \cdot 10^{-5})]= \\ 
[2.326 \cdot 10^{-4}, 3.848 \cdot10^{-4}].
$$
This can also be confirmed by the built-in function `confint()` in R:

```{r echo=FALSE}
int=confint(modelA,level = 0.99)
int[5,]

```

When interpreting the confidence interval, it can be useful to consider the accuracy of our estimation, for example the standard error of the parameter. In this case, $SE(\hat\beta_{BMI})=(2.955 \cdot 10^{-5})$. This is a factor $10$ smaller than the estimated parameter itself. With this in mind, it is quite safe to assume that $\beta_{BMI}$ is far enough from zero to conclude that according to `modelA`, there is in fact a connection between the BMI and the response. 

Can we know anything about the p-value for a hypothesis test? In words, the null hypothesis $H_0: \beta_{BMI}=0$ is saying that "there is no relationship between $\beta_{BMI}$ and $-1/\sqrt{SYSBP}$".
We are 99 % confident that our $\beta_{BMI}$ lies in an interval not containg zero, i.e. we are 99 % confident that there in fact is a relationship. The p-value is, assuming the zero-hypothesis is true, the probability of not observing a linear connection between the response and $\beta_{BMI}$. Since the confidence interval calculated above says that we are quite confident that our zero-hypothesis should be rejected (there is a connection between $Y$ and $\beta_{BMI}$), we would expect the p-value to be small. More exact, one can assume that the p-value will be smaller than 0.01. This is also confirmed by the R-code above, where the p-value is calculated to be less than $2\cdot10^{-16}$.
 
###Task d)
 
Now, we are considering a new observation, namely 
```{r, echo=FALSE}

data = read.table("https://www.math.ntnu.no/emner/TMA4268/2018v/data/SYSBPreg3uid.txt")

modelA=lm(-1/sqrt(SYSBP) ~ .,data = data)
new=data.frame(SEX=1,AGE=56,CURSMOKE=1,BMI=89/1.75^2,TOTCHOL=200,BPMEDS=0)
new=cbind(1,new)
new
```

Using `modelA`, one obtain the value $0.0867$ for his $1/\sqrt{SYSBP}$ and $133$ for his $SYSBP$. The code output is shown below.

```{r, echo=FALSE}
Y=coef(modelA)%*%t(new)
Y
bp=(1/(-Y)^2)
bp
```
We want to construct a 90% prediction interval for our prediction, and name the prediction for the response $\mathbf{\hat{Y}}=\mathbf{x_0^T}\boldsymbol{\beta}$. The expression for the prediction interval for $\mathbf{Y}$:

$$
P( \mathbf{x_0^T}\boldsymbol{\hat\beta} - t_{\alpha/2,n-p-1} \hat\sigma^2 \sqrt{1+\mathbf{x_0^T}\mathbf{(X^TX)^{-1}\mathbf{x_0}}} \leq \mathbf{Y_0} \leq\mathbf{x_0^T}\boldsymbol{\hat\beta} - t_{\alpha/2,n-p-1} \hat\sigma^2 \sqrt{1+\mathbf{x_0^T}\mathbf{(X^TX)^{-1}\mathbf{x_0}}} ) = 1-\alpha \\ 
$$
Where $\mathbf{x_0}$ is the covariates measured, $p$ is the number of covariates.
So a prediction interval for our response can be expressed as
$$
[\mathbf{x_0^T}\boldsymbol{\hat\beta} - t_{\alpha/2,n-p-1} \hat\sigma^2 \sqrt{1+\mathbf{x_0^T}\mathbf{(X^TX)^{-1}\mathbf{x_0}}}, \mathbf{x_0^T}\boldsymbol{\hat\beta} - t_{\alpha/2,n-p-1} \hat\sigma^2 \sqrt{1+\mathbf{x_0^T}\mathbf{(X^TX)^{-1}\mathbf{x_0}}}]
$$
The R-function ´predict()´ gives the $90$% rpediction interval
We construct a 90% prediction interval for the new observation: 
```{r, echo=FALSE}
data = read.table("https://www.math.ntnu.no/emner/TMA4268/2018v/data/SYSBPreg3uid.txt")

modelA=lm(-1/sqrt(SYSBP) ~ .,data = data)
new=data.frame(SEX=1,AGE=56,CURSMOKE=1,BMI=89/1.75^2,TOTCHOL=200,BPMEDS=0)
new=cbind(1,new)
predict(modelA,new,interval='predict',level=0.90)
```
Transformed to `SYSBP`, we get the prediction interval
$[107.9, 168.28]$.

The prediction interval tells us that we are 90 % confident that the true `SYSBP` will lie in the interval. The interval is not very accurate, and thus not very informative as most peoples `SYSBP` will in fact lie in this interval. In addition, when calculating the prediction interval for the $-1/\sqrt{SYSBP}$ prior to the transformation to `SYSBP`, one will not obtain the correct 90% prediction interval for the `SYSBP`, because the realtionship between the two is not linear. This is also easily observed, as our `SYSBP` prediction is not the centre of the `SYSBP` 90% PI.





