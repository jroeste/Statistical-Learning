\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Compulsory exercise 2: Group 19},
            pdfauthor={Ida Marie Falnes, Astrid Langsrud and Julie Røste},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{Compulsory exercise 2: Group 19}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
\subtitle{TMA4268 Statistical Learning V2018}
  \author{Ida Marie Falnes, Astrid Langsrud and Julie Røste}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \predate{\centering\large\emph}
  \postdate{\par}
  \date{14 mars, 2018}


\begin{document}
\maketitle

\subsection{1a)}\label{a}

Q1: There are in total \(2^d\) different linear regression models that
can be fitted when we have d predictors. This is due to the two choices
we have for each covariate, either we can have it in our model or not.
Another way to come up with the same result is to look at the different
models for each complexity. First we have to fit all the d models that
contain 1 predictor, then all \(\binom{d}{2}=d(d-1)/2\) models that
contain 2 predictors, all \(\binom{d}{3}=d(d-1)(d-2)/3!\) that contain 3
predictors and so on up to \(\binom{d}{d}=1\). Summing up all these
combinations in addition to the ``null model'', the model where have no
predictors, we get \[\sum_{k=0}^{d} \binom{d}{k} = ... = 2^d.\] Here we
used the binomial theorem \(\sum_{k=0}^{d}\binom{d}{k}x^k=(1+x)^d\) with
\(x=1\).

Q2: To choose the best model out of all possibilities we both need to
consider the residual sum of squares (RSS) between models with equal
amount of predictors and the BIC-criterion to choose among the best
models for every number of predictors. This is presented in the
following algorithm:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  For \(k=0,1,2,...,d\): \newline
  Fit all \(\binom{d}{k}\) models that contain exactly k predictors.
  Then find the model with smallest RSS (largest \(R^2\)) and call it
  \(\mathcal{M}_k\). For the case with \(k=0\), we get
  \(\mathcal{M}_0\), which simply predicts the sample mean for each
  observation.
\item
  Select the best model among \(\mathcal{M}_0, ...,\mathcal{M}_d\) using
  the BIC-criterion, where
  \(\text{BIC}=\frac{1}{n}(RSS+log(n)k{\hat\sigma}^2)\) with
  \({\hat\sigma}^2\) as an unbiased estimator for the variance.
\end{enumerate}

If we instead of BIC simply used \(R^2\) as our base for selecting a
model, we would get a good training error, but a poor test error. This
is because the training error will decrease as more variables are
included in the model, and we surely get a model with as many predictors
as possible, which may cause overfitting. However, \(R^2\) is good when
comparing models with the same numbers of predictors, as in part 1 of
the algorithm.

\subsection{1b)}\label{b}

Q3: As explained in the theory, the best model for each model complexity
is chosen by taking the one with smallest RSS-value for a given number
of predictors. The best model for computing miles pr gallon with two
covariates is the one with \texttt{weight} and \texttt{year}.

Q4: To choose between the different models \(\mathcal{M}_0\) to
\(\mathcal{M}_d\), we choose the one with smallest BIC-value. Here the
BIC-value corresponding to the best model is \(-520\). Looking at the
black fields, we should choose the model with these seven covariates:
intercept, cylinders, displace, horsepower, weight, year, origin2 and
origin3.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}
\KeywordTok{library}\NormalTok{(nortest)}
\CommentTok{#Fit the model with all covariates except `acceleration`.}
\NormalTok{ourAutofit.lm=}\KeywordTok{lm}\NormalTok{(mpg}\OperatorTok{~}\NormalTok{.}\OperatorTok{-}\NormalTok{acceleration,}\DataTypeTok{data=}\NormalTok{ourAutoTrain)}
\KeywordTok{summary}\NormalTok{(ourAutofit.lm)}
\NormalTok{MSE_train=}\KeywordTok{mean}\NormalTok{((ourAutofit.lm}\OperatorTok{$}\NormalTok{residuals)}\OperatorTok{^}\DecValTok{2}\NormalTok{)}

\KeywordTok{ad.test}\NormalTok{(}\KeywordTok{rstudent}\NormalTok{(ourAutofit.lm))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = mpg ~ . - acceleration, data = ourAutoTrain)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.7254 -2.0561 -0.3412  1.7122 12.9550 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(>|t|)    
## (Intercept)         -1.941e+01  4.589e+00  -4.230 3.09e-05 ***
## cylinders(5.5,8.01] -3.533e+00  7.469e-01  -4.730 3.43e-06 ***
## displace             3.279e-02  6.749e-03   4.858 1.90e-06 ***
## horsepower          -4.883e-02  1.184e-02  -4.124 4.80e-05 ***
## weight              -5.824e-03  6.185e-04  -9.415  < 2e-16 ***
## year                 7.849e-01  5.699e-02  13.771  < 2e-16 ***
## origin2              1.794e+00  6.204e-01   2.892  0.00411 ** 
## origin3              2.906e+00  5.943e-01   4.891 1.63e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.233 on 305 degrees of freedom
## Multiple R-squared:  0.8344, Adjusted R-squared:  0.8306 
## F-statistic: 219.6 on 7 and 305 DF,  p-value: < 2.2e-16
## 
## 
##  Anderson-Darling normality test
## 
## data:  rstudent(ourAutofit.lm)
## A = 2.2684, p-value = 9.241e-06
\end{verbatim}

As seen in the summary, we get estimates for the \(\hat\beta\)'s. In
general the estimates for \(\hat\beta\)'s vary between order \(10^{-3}\)
and 10. The standard error is largest for the intercept, and compared to
the size of the estimates, . When looking at the p-values for the
covariates, all are below the significane level, \(\alpha=0.05\), which
means that we should believe there is a linear dependence between
\texttt{miles\ per\ gallon} and the covariates. Among the covariates,
\texttt{weight} and \texttt{year} have the lowest p-values. Also, the
\(R^2\)-value is relatively close to 1. On the other hand, the Anderson
Darling Normality test gives us a p-value of order \(10^{-6}\) which
indicates that the errors might not be normal distributed and that the
linear linear dependence not is that good. The MSE on
\texttt{ourAutoTrain} is

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{MSE_train}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 10.18351
\end{verbatim}

Q5: The predicted new values for \(\hat Y\) are computed by
\texttt{predict} and we get the following value for the MSE for the test
set.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y_hat=}\KeywordTok{predict.lm}\NormalTok{(ourAutofit.lm,ourAutoTest)}
\NormalTok{MSE_test=}\KeywordTok{mean}\NormalTok{((y_hat}\OperatorTok{-}\NormalTok{ourAutoTest}\OperatorTok{$}\NormalTok{mpg)}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\NormalTok{MSE_test}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8.931018
\end{verbatim}

\subsection{1c)}\label{c}

Q6: \(k\)-fold cross validation is performed by randomly dividing the
data set consisting of \(n\) observations into \(k\) approximately
equally sized groups, or \(folds\). One of these folds is left out and
kept as a validation set, and the remaining \(k-1\) folds are used to
fit the model. Then the validation set is used to calculate the mean
squared error (\(MSE\)) for the fitted model. The process is repated
\(k\) times, so an \(MSE\) is calculated for each fold. If \(n\) is a
multiple of \(k\), we have in average \(n_k=n/k\) and the formula for
\(MSE_k\) is

\[
MSE_k=\frac{1}{n_k}\sum_{i \in C_k}(y_i-\hat y_i)^2,
\]

where \(C_k\) denotes the held-out fold \(k\), \(\hat y_i\) is the fit
obtained when holding out data from \(C_k\), and \(n_k\) is the number
of observations in fold \(k\).

The final CV estimate is the average of all the \(k\) MSEs:

\[
CV_k=\sum_{j=1}^k \frac{n_j}{n}MSE_j,
\] where \(\text{MSE}_j\) is given by the equation above. Q7. Why
\(k\)-fold cross-validation may be preferred to leave-one-out
cross-validation: LOOCV is k-fold CV when \(k=n\). When \(k\) is
substantially smaller than \(n\), it follows that LOOCV usually is
computationally more expensive than \(k\)-fold. This is because for the
LOOCV \(n\) different models is fitted, as opposed to only \(k\) models
in \(k\)-fold. In practice \(k=5\) or \(k=10\) is most common, as these
values has turned out to give the best compromise between bias and
variance, as we will discuss next.

Another reason for preferring \(k\)-fold CV over LOOCV comes from the
bias-variance trade-off. LOOCV will have a low bias, but a rather high
variance comapred to \(k\)-fold CV. This follows from the procedure of
cross validation. One averages over model fits that consists of almost
the same set of observations; only one observation differ for each
model. This will cause high correlation between each model. When
averaging over values, the higher correlated these are, the higher will
the variance be. From this rationale, one can conclude that the models
in \(k\)-fold cross-validation will be trained on less overlapping
training data and will have less variance than the LOOCV.

\subsection{1d)}\label{d}

Q8: R code to perform a 10-fold cross-validation is used with the best
subset method on \texttt{ourAutoTrain}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(caret)}
\KeywordTok{library}\NormalTok{(leaps)}
\CommentTok{#Predict function}
\NormalTok{predict.regsubset =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(object, newdata, id)\{}
\NormalTok{  form=}\KeywordTok{as.formula}\NormalTok{(object}\OperatorTok{$}\NormalTok{call[[}\DecValTok{2}\NormalTok{]])}
\NormalTok{  mat=}\KeywordTok{model.matrix}\NormalTok{(form,newdata)}
\NormalTok{  coefi=}\KeywordTok{coef}\NormalTok{(object,}\DataTypeTok{id=}\NormalTok{id)}
\NormalTok{  xvars=}\KeywordTok{names}\NormalTok{(coefi)}
\NormalTok{  mat[,xvars]}\OperatorTok{%*%}\NormalTok{coefi}
\NormalTok{\}}
\CommentTok{#10-fold cross-validation}
\NormalTok{k=}\DecValTok{10}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{4268}\NormalTok{)}
\NormalTok{folds=}\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{k,}\KeywordTok{nrow}\NormalTok{(ourAutoTrain),}\DataTypeTok{replace=}\OtherTok{TRUE}\NormalTok{)}
\NormalTok{cv.errors=}\KeywordTok{matrix}\NormalTok{(}\OtherTok{NA}\NormalTok{,k,}\DecValTok{8}\NormalTok{,}\DataTypeTok{dimnames=}\KeywordTok{list}\NormalTok{(}\OtherTok{NULL}\NormalTok{,}\KeywordTok{paste}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{8}\NormalTok{)))}

\CommentTok{#Perform crossvalidation:}
\ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{k)\{}
\NormalTok{  best.fit=}\KeywordTok{regsubsets}\NormalTok{(mpg}\OperatorTok{~}\NormalTok{.,}\DataTypeTok{data=}\NormalTok{ourAutoTrain[folds}\OperatorTok{!=}\NormalTok{j,],}\DataTypeTok{nvmax=}\DecValTok{8}\NormalTok{)}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{8}\NormalTok{)\{}
\NormalTok{    pred=}\KeywordTok{predict.regsubset}\NormalTok{(best.fit,ourAutoTrain[folds}\OperatorTok{==}\NormalTok{j,],}\DataTypeTok{id=}\NormalTok{i)}
\NormalTok{    cv.errors[j,i]=}\KeywordTok{mean}\NormalTok{((ourAutoTrain}\OperatorTok{$}\NormalTok{mpg[folds}\OperatorTok{==}\NormalTok{j]}\OperatorTok{-}\NormalTok{pred)}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{\}}
\CommentTok{#Compute mean of cross-validation errors}
\NormalTok{mean.cv.errors=}\KeywordTok{apply}\NormalTok{(cv.errors,}\DecValTok{2}\NormalTok{,mean)}
\NormalTok{mean.cv.errors}
\NormalTok{num_cov=}\KeywordTok{which.min}\NormalTok{(mean.cv.errors)}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(mean.cv.errors,}\DataTypeTok{type=}\StringTok{"b"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{project2_MASTER_files/figure-latex/unnamed-chunk-5-1.pdf}

\begin{verbatim}
##        1        2        3        4        5        6        7        8 
## 20.04605 11.98844 11.92601 11.29254 11.71515 10.72818 10.56209 10.61032
\end{verbatim}

Q9. The optimal model complexity is with 7 covariates, just as in 1b),
as we see from the list of averaged cross-validation errors with lowest
value 10.562.

Q10. Since we get the same model complexity from 10-fold
cross-validation as with the best subset method, we get the same
coefficients for the \(\hat\beta\)'s. The new values for
\texttt{ourAutoTest} are the same as in Q4 and Q5, as well as the MSE
for the test set.

\subsection{2a) Explain figures}\label{a-explain-figures}

Q11: The first figure corresponds to Lasso, and the second figure
corresponds to Ridge regression.

This can be concluded from the fact that the coefficient values in
figure 1 becomes zero for large enough value of \(\lambda\), which is
only possible for Lasso and not for Ridge regression. In Ridge
regression the coefficient values only approaches zero as \(\lambda\)
grows, which is corresponding to figure 2.

Q12: The tuning parameter penalizes values of the estimated coefficients
\(\beta\), resulting in a reduction of the sum of the absolute values of
the coefficients. When the value of \(\lambda\) grows, this reduction
also grows.

This can be seen from the minimization formulas for Ridge regression and
Lasso, as they include the terms \(\lambda \sum_{j=1}^p \beta_j^2\) and
\(\lambda \sum_{j=1}^p |\beta_j|\) respectively. These terms favors
\(\beta\)-values close to zero for minimization, and their fraction of
the expressions depend on the value of \(\lambda\).

This can also be seen from the figures as these displays how the
coefficient values vary with \(\lambda\). The standardized coefficients
tends towards zero as \(\lambda\) increases.

Increasing lambda will result in less flexibility of the model. As a
consequence, increasing lambda means reducing variance and increasing
bias.

When \(\lambda \rightarrow \infty\) the \(\beta\)-values will approach
zero in Ridge regression and become zero in Lasso in order to minimize
the model expressions. When \(\lambda = 0\) both Ridge regression and
Lasso will produce the same output as ordinary least squares estimate,
as the penalty term is removed.

Q13:

For Lasso the coefficients eventually become zero when \(\lambda\) is
large enough, and thus the method results in model selection. On the
other hand in Ridge regression the coefficients will not become zero,
and thus it does not perform model selection.

In problem 1b, BIC is used to compare models with different number of
included variables. For each number of included variables the best model
is found, and these are compared. From the figure in exercise 1b it is
seen that weight, year and cylinders are the variables that are included
in most of the models, indicating that these are important for the
model. In figure 1 both year and cylinders need a relatively high
\(\lambda\)-value to become zero. Weight has a very low coefficient
value, and thus it is difficult to see when it becomes zero. In figure 2
it also seems like cylinder needs a relatively large \(\lambda\)-value
to become zero. Here it is difficult to say much about year since this
has a lower coefficient value initially. However, it seems like the some
of the same trends of relative importance of the variables are captured
in by the different methods.

The best model according to the method in 1b is that where only the
acceleration variable is excluded. On the other hand, for a high enough
\(\lambda\)-value many variables are excluded in Lasso, and many
variables approach zero in Ridge regression. This indicate that low
\(\lambda\)-values gives models from Lasso and Ridge that is most
similar to the best model found using BIC.

\includegraphics{project2_MASTER_files/figure-latex/unnamed-chunk-6-1.pdf}

\subsection{\texorpdfstring{2b) Finding the optimal
\(\lambda\)}{2b) Finding the optimal \textbackslash{}lambda}}\label{b-finding-the-optimal-lambda}

Q14: According to the description of the R-package glmnet, it ``fits a
generalized linear model via penalized maximum likelihood''. cv.glmnet
does k-fold cross-validation of the glmnet to produce the MSE for
different \(\lambda\)-values.

Q15: The plot shows how the MSE vary with the value of lambda. We want
the MSE to be as small as possible, but we also want regularization to
get a simpler model. Thus, two optimal \(\lambda\)-values are suggested
by the plot, shown by a dotted line. The leftmost is that with lowest
MSE value, and the other is 1se which correspond to the highest
\(\lambda\)-value such that the MSE not more than one standard error
away from the minimum.

Q16:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(glmnet)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{4268}\NormalTok{)}

\NormalTok{x=}\KeywordTok{model.matrix}\NormalTok{(mpg}\OperatorTok{~}\NormalTok{.,ourAutoTrain)[,}\OperatorTok{-}\DecValTok{1}\NormalTok{] }\CommentTok{#-1 to remove the intercept.}
\NormalTok{y=ourAutoTrain}\OperatorTok{$}\NormalTok{mpg}

\NormalTok{lambda=}\KeywordTok{c}\NormalTok{(}\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from=}\DecValTok{5}\NormalTok{,}\DataTypeTok{to=}\FloatTok{0.1}\NormalTok{,}\DataTypeTok{length.out=}\DecValTok{150}\NormalTok{),}\FloatTok{0.01}\NormalTok{,}\FloatTok{0.0001}\NormalTok{) }\CommentTok{#Create a set of tuning parameters, adding low value to also see least squares fit}
\NormalTok{cv.out=}\KeywordTok{cv.glmnet}\NormalTok{(x,y,}\DataTypeTok{alpha=}\DecValTok{1}\NormalTok{,}\DataTypeTok{nfolds=}\DecValTok{10}\NormalTok{,}\DataTypeTok{lambda=}\NormalTok{lambda, }\DataTypeTok{standardize=}\OtherTok{TRUE}\NormalTok{) }\CommentTok{#alpha=1 gives lasso, alpha=0 gives ridge}
\end{Highlighting}
\end{Shaded}

The \(\lambda\)-value that gives lowest MSE is

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cv.out}\OperatorTok{$}\NormalTok{lambda.min}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1e-04
\end{verbatim}

And the value that corresponds to 1se is

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{L =}\StringTok{ }\NormalTok{cv.out}\OperatorTok{$}\NormalTok{lambda.1se}
\NormalTok{cv.out}\OperatorTok{$}\NormalTok{lambda.1se}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.01
\end{verbatim}

We chose the last one to be the optimal \(\lambda\), and we will use
this for the next exercise.

\subsection{2c) Prediction}\label{c-prediction}

Q17: Fitting a model with lasso using \(\lambda = 0.01\) gives the
following coefficients

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lasso =}\StringTok{ }\KeywordTok{glmnet}\NormalTok{(x, y, }\DataTypeTok{alpha=}\DecValTok{1}\NormalTok{, }\DataTypeTok{lambda =}\NormalTok{ L)}

\KeywordTok{coef}\NormalTok{(lasso)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 9 x 1 sparse Matrix of class "dgCMatrix"
##                                s0
## (Intercept)         -21.475534414
## cylinders(5.5,8.01]  -3.383985180
## displace              0.031030021
## horsepower           -0.035228794
## weight               -0.006084397
## acceleration          0.124425729
## year                  0.782180280
## origin2               1.676410824
## origin3               2.832044860
\end{verbatim}

Thus the model is

\[
\hat{Y} = -21.5 -3.38x_{cylinders} + 0.031x_{displace} - 0.035x_{horsepower}
\]

\[
-0.0061x_{weight}+0.12x_{acceleration} +0.78x_{year}+1.68x_{origin2}+2.83x_{origin3}
\]

Q18:

The predicted mpg for the car with displace=150, horsepower=100,
weight=3000, acceleration=10, year=82 and comes from Europe is

\begin{verbatim}
##             1
## [1,] 28.46235
\end{verbatim}

\subsection{3a)}\label{a-1}

Q19: Fitting the specified \texttt{gam}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(gam)}
\KeywordTok{library}\NormalTok{(ISLR)}
\KeywordTok{library}\NormalTok{(GGally)}
\KeywordTok{library}\NormalTok{(leaps)}
\KeywordTok{library}\NormalTok{(glmnet)}
\KeywordTok{library}\NormalTok{(ggplot2)}
\NormalTok{gamobject <-}\StringTok{ }\KeywordTok{gam}\NormalTok{(mpg}\OperatorTok{~}\KeywordTok{bs}\NormalTok{(displace, }\DataTypeTok{knots =} \DecValTok{290}\NormalTok{)}\OperatorTok{+}\KeywordTok{poly}\NormalTok{(horsepower,}\DecValTok{2}\NormalTok{)}\OperatorTok{+}
\StringTok{                   }\NormalTok{weight}\OperatorTok{+}\KeywordTok{s}\NormalTok{(acceleration, }\DecValTok{3}\NormalTok{)}\OperatorTok{+}\NormalTok{origin,}\DataTypeTok{data=}\NormalTok{ourAutoTrain)}

\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(gamobject,}\DataTypeTok{se=}\OtherTok{TRUE}\NormalTok{,}\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{project2_MASTER_files/figure-latex/unnamed-chunk-12-1.pdf}
The resulting plots shows the fitted GAM with five components, in
addition to the pointwise standard errors for each feature. In general,
GAM-plots shows how the response, in our case the \texttt{mpg}, will
vary when holding all but one of the variables constant. This is done
for all five variables.

Upper left: A cubic spline in \texttt{displace} with one knot at 290.
The plot shows that when increasing \texttt{displace} from 0 to 400,
there is on average a decrease of \texttt{mpg}. The curve indicates that
the response decreases faster for \texttt{displace}-values between 0 and
290. At the knot at 290, there seems to be a local minimum and the
change in the response will slightly increase until 400, where further
increasing engine displacement will lead to a more rapid decreasement of
miles per gallon. Note that there are fewer observations from about 300
on the \texttt{displace}-axis, so error curves in this area is quite
large. In addition, the model will in general be based on fewer data
points in the beginning and end intervals. This is because there are no
data points outside of the interval.

Top row, middle plot: A polynomial of degree 2 of \texttt{mpg} as a
function of \texttt{horsepower}. The plot shows that an increase in
horsepower will on average deacrease the use of miles per gallon. As in
the previous plot, we also observe larger errors in the boundaries which
can be explained by fewer observations in the ends of the curve. (almost
no data points \textgreater{}200).

Upper right: Linear regression fit using \texttt{weight} as predictor.
The fitted curve indicates that an increase in weight will on average
lead to a decrease in \texttt{mpg}. The error curves are also linear and
larger in the endpoints.

lower left: A smoothing spline with 3 degrees of freedom. Most of the
data points lies in the area between 13 and 20. Here, the curve
indicates that for increased acceleration of the car, the \texttt{mpg}
will decrease. Few observations in the endpoints lead to large error
curves here.

Lower right: Step function. We have observed more american vehicles, and
the variance is much smaller for the these cars. On average the European
cars have less \texttt{mpg} than Americans, that in turn use slighty
less than the Japanese cars, according to our data.

Q20: We have an order \(M=4\) spline with \(K=1\) knot. In general we
will have \(M+K-1=4\) basis functions. In our case, the basis the cubic
spline is \(X,X^2,X^3,(x-c_1)_+^3\). The truncated power function is

\[
(x-290)^3= \begin{cases}(x-290)^3, x>290 \\
0, \text{otherwise}
\end{cases}
\] for the knot \(c_1=290\).


\end{document}
